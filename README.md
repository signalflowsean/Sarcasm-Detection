# [Sarcasm Detector‚Ñ¢](https://sarcasm-detector.com)

> _A signalflowsean production_

A full-stack web application that detects sarcasm in text and audio using machine learning. Features a beautiful retro VU meter-style interface with animated needle displays.

![Sarcasm Detector](https://img.shields.io/badge/status-in%20development-yellow)
![License](https://img.shields.io/badge/license-MIT-blue)

## Overview

The Sarcasm Detector analyzes input through two detection modes:

- **Lexical Detection** ‚Äî Analyzes _what_ you say (text-based)
- **Prosodic Detection** ‚Äî Analyzes _how_ you say it (audio-based)

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Frontend (React)                       ‚îÇ
‚îÇ                   Port 80 (Production)                      ‚îÇ
‚îÇ                   Port 5173 (Development)                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                       ‚îÇ                                     ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ    ‚îÇ         Flask Backend               ‚îÇ                 ‚îÇ
‚îÇ    ‚îÇ           Port 5000                 ‚îÇ                 ‚îÇ
‚îÇ    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ                 ‚îÇ
‚îÇ    ‚îÇ  ‚îÇ  /api/     ‚îÇ  /api/prosodic ‚îÇ   ‚îÇ                 ‚îÇ
‚îÇ    ‚îÇ  ‚îÇ  lexical   ‚îÇ                ‚îÇ   ‚îÇ                 ‚îÇ
‚îÇ    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ                 ‚îÇ
‚îÇ    ‚îÇ         ‚îÇ             ‚îÇ            ‚îÇ                 ‚îÇ
‚îÇ    ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ                 ‚îÇ
‚îÇ    ‚îÇ    ‚îÇ TF-IDF  ‚îÇ   ‚îÇWav2Vec2 ‚îÇ      ‚îÇ                 ‚îÇ
‚îÇ    ‚îÇ    ‚îÇ+ LogReg ‚îÇ   ‚îÇ+ LogReg ‚îÇ      ‚îÇ                 ‚îÇ
‚îÇ    ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ                 ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Quick Start

### Prerequisites

- **Python 3.11** (required for backend)
  - The backend requires Python 3.11 to match CI/CD and production environments
  - If using [pyenv](https://github.com/pyenv/pyenv), the `.python-version` file in `backend/` will automatically set the correct version
  - Verify your Python version: `python3 --version` (should be 3.11.x)
- **Node.js 20+** (for frontend and e2e tests)
- **npm** or **yarn**

### Install (One-Time Setup)

```bash
# Install all dependencies (backend, frontend, and e2e)
npm run install:all
```

Or install individually:

```bash
npm run install:backend  # Python venv + dependencies (requires Python 3.11)
npm run install:frontend # Frontend npm packages
npm run install:e2e      # E2E test dependencies
```

> **Note:** Git hooks are automatically configured during installation via the `prepare` script. This sets up Husky to run `lint-staged` on pre-commit, which will automatically lint and format your staged files before committing. No manual setup required!

> **Python Version:** The backend requires Python 3.11. If you're using pyenv, ensure Python 3.11 is installed (`pyenv install 3.11`) and the `.python-version` file in `backend/` will automatically activate it. If your system Python is not 3.11, you may need to recreate the virtual environment: `cd backend && rm -rf venv && python3.11 -m venv venv && source venv/bin/activate && pip install -r requirements.txt`

### Development (Recommended)

Start both servers with hot reload:

```bash
# Backend (Terminal 1)
cd backend
source venv/bin/activate  # or venv\Scripts\activate on Windows
python app.py

# Frontend (Terminal 2)
cd frontend
npm run dev

# Or use the root helper script (no venv activation needed)
npm run dev
```

> **Note:** The backend will start successfully without the `wav2vec2.onnx` file, but prosodic (audio-based) detection will return fallback values. For full functionality, export the ONNX model (see [Model Training](#model-training) section).

### E2E Tests

```bash
# Make sure dev servers are running, then:
npm run e2e
```

### Docker (Production Build)

Only needed for testing production builds:

```bash
docker compose up --build
```

## Project Structure

```
Sarcasm-Detection/
‚îú‚îÄ‚îÄ backend/                    # Flask API server
‚îÇ   ‚îú‚îÄ‚îÄ app.py                 # Main application & API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ audio/                 # Audio processing module
‚îÇ   ‚îú‚îÄ‚îÄ models/                # ML model loading & inference
‚îÇ   ‚îú‚îÄ‚îÄ routes/                # API route blueprints
‚îÇ   ‚îú‚îÄ‚îÄ tests/                 # Backend unit tests (pytest)
‚îÇ   ‚îú‚îÄ‚îÄ sarcasm_model.pkl      # Trained lexical model
‚îÇ   ‚îú‚îÄ‚îÄ prosodic_model.pkl     # Trained prosodic model
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ requirements-dev.txt   # Dev/test dependencies
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile             # Backend container configuration
‚îÇ
‚îú‚îÄ‚îÄ frontend/                   # React + TypeScript + Vite application
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ input/         # Text & audio input components
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ meter/         # VU meter display components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test/              # Test setup & mocks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx            # Main application component
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.tsx           # Application entry point
‚îÇ   ‚îú‚îÄ‚îÄ vitest.config.ts       # Vitest test configuration
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile             # Frontend container configuration
‚îÇ   ‚îî‚îÄ‚îÄ nginx.conf             # Production server configuration
‚îÇ
‚îú‚îÄ‚îÄ e2e/                        # End-to-end tests (Playwright)
‚îÇ   ‚îú‚îÄ‚îÄ tests/                 # E2E test specs
‚îÇ   ‚îî‚îÄ‚îÄ playwright.config.ts   # Playwright configuration
‚îÇ
‚îú‚îÄ‚îÄ scripts/                    # Utility scripts
‚îÇ   ‚îî‚îÄ‚îÄ version.js            # Version increment script
‚îÇ
‚îú‚îÄ‚îÄ ml/                         # Machine learning training pipelines
‚îÇ   ‚îú‚îÄ‚îÄ lexical/               # Text-based sarcasm detection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_sklearn_model.py  # TF-IDF + LogReg (production)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inference.py       # Test utility
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md          # Detailed documentation
‚îÇ   ‚îú‚îÄ‚îÄ prosodic/              # Audio-based sarcasm detection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mustard_prepare.py     # Dataset preparation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mustard_embeddings.py  # Wav2Vec2 embedding extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_prosodic.py      # Model training
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inference.py           # Test utility
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md              # Detailed documentation
‚îÇ   ‚îî‚îÄ‚îÄ README.md              # ML overview
‚îÇ
‚îú‚îÄ‚îÄ .github/                    # GitHub configuration
‚îÇ   ‚îî‚îÄ‚îÄ workflows/             # GitHub Actions workflows
‚îÇ       ‚îú‚îÄ‚îÄ ci.yml             # CI pipeline (linting, tests, Docker builds)
‚îÇ       ‚îú‚îÄ‚îÄ e2e.yml            # End-to-end test workflow
‚îÇ       ‚îî‚îÄ‚îÄ version.yml        # Auto-version increment on PR
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml         # Multi-container orchestration
‚îî‚îÄ‚îÄ README.md                  # This file
```

## Model Training

Pre-trained models are included in `backend/`. To retrain from scratch:

```bash
# Lexical model (quick, auto-downloads data)
cd ml/lexical
pip install -r requirements.txt
python train_sklearn_model.py

# Prosodic model (requires ~2GB video download)
cd ml/prosodic
pip install -r requirements.txt
brew install ffmpeg  # or: sudo apt install ffmpeg
python mustard_prepare.py      # Download & extract audio
python mustard_embeddings.py   # Extract Wav2Vec2 embeddings
python train_prosodic.py       # Train classifier

# Export ONNX model for backend deployment (optional but recommended)
pip install torch transformers onnx onnxruntime
python export_onnx.py
# Copy wav2vec2.onnx to backend/ directory
cp wav2vec2.onnx ../../backend/
```

See [ml/README.md](ml/README.md) for detailed documentation.

## API Endpoints

### `POST /api/lexical`

Lexical (text-based) sarcasm detection.

**Request:**

```json
{
  "text": "Oh great, another meeting that could have been an email"
}
```

**Response:**

```json
{
  "id": "uuid-string",
  "value": 0.85,
  "reliable": true
}
```

### `POST /api/prosodic`

Prosodic (audio-based) sarcasm detection.

**Request:** `multipart/form-data` with `audio` file

**Response:**

```json
{
  "id": "uuid-string",
  "value": 0.72,
  "reliable": true
}
```

> **Note:** The `reliable` field indicates whether the prediction came from the actual ML model (`true`) or is a fallback value due to model unavailability (`false`). When `reliable` is `false`, the UI displays a warning to users.

### `GET /api/health`

Health check endpoint for container orchestration.

**Response:**

```json
{
  "status": "healthy",
  "version": "1.0.0",
  "models": {
    "lexical": true,
    "prosodic": false,
    "wav2vec_onnx": false
  }
}
```

> **Note:** The `models` field indicates which ML models are currently loaded and available. `prosodic` and `wav2vec_onnx` will be `false` if the ONNX model file (`wav2vec2.onnx`) is not present - the prosodic endpoint will still work but return fallback values.

## Technology Stack

| Layer          | Technology                                  |
| -------------- | ------------------------------------------- |
| Frontend       | React 19, TypeScript, Vite, React Router    |
| Backend        | Flask, Flask-CORS, Flask-Limiter, Gunicorn  |
| Python         | Python 3.11 (required)                      |
| ML (Lexical)   | scikit-learn (TF-IDF + Logistic Regression) |
| ML (Prosodic)  | Wav2Vec2 (ONNX Runtime) + scikit-learn      |
| Testing        | Vitest, Playwright, pytest                  |
| Infrastructure | Docker, Docker Compose, Nginx               |

## Development

### Environment Variables

**Backend:**

| Variable              | Default         | Description                                                                   |
| --------------------- | --------------- | ----------------------------------------------------------------------------- |
| `API_DELAY_SECONDS`   | `2.0`           | Artificial delay for showcasing loading animations (set to `0` in production) |
| `FLASK_ENV`           | `production`    | Flask environment mode                                                        |
| `FFMPEG_TIMEOUT`      | `30`            | FFmpeg conversion timeout in seconds (prevents hanging on corrupted files)    |
| `PRELOAD_MODELS`      | `true`          | Preload ML models at startup (set to `false` for faster dev startup)          |
| `RATE_LIMIT_ENABLED`  | `true`          | Enable/disable rate limiting                                                  |
| `RATE_LIMIT_DEFAULT`  | `60 per minute` | Default rate limit for all endpoints                                          |
| `RATE_LIMIT_LEXICAL`  | `30 per minute` | Rate limit for text analysis endpoint                                         |
| `RATE_LIMIT_PROSODIC` | `10 per minute` | Rate limit for audio analysis endpoint                                        |
| `RATE_LIMIT_STORAGE`  | `memory://`     | Storage backend (`memory://` or `redis://host:port`)                          |

**Frontend:**

| Variable               | Default                 | Description                                             |
| ---------------------- | ----------------------- | ------------------------------------------------------- |
| `VITE_API_URL`         | `http://localhost:5000` | Backend API URL                                         |
| `VITE_MOONSHINE_MODEL` | `model/base`            | Speech recognition model (`model/tiny` or `model/base`) |

#### Moonshine Speech Recognition Configuration

The app uses [Moonshine](https://www.moonshine.ai/) for on-device speech-to-text. Models are downloaded once and cached by the browser.

**Why Moonshine?** The Web Speech API isn't fully implemented across mobile browsers (especially iOS Safari). Moonshine provides consistent speech-to-text behavior across all platforms with predictable accuracy.

**Available Models:**

| Model        | Size   | Accuracy (WER) | Use Case                    |
| ------------ | ------ | -------------- | --------------------------- |
| `model/tiny` | ~190MB | 15-20%         | Fast, mobile-friendly       |
| `model/base` | ~400MB | 10-12%         | **Default** - Best accuracy |

**Default:** `model/base` for better speech-to-text accuracy, which improves the lexical detection component. The app combines both lexical (text-based) and prosodic (audio-based) detection for overall sarcasm scoring.

**Switching Models:**

1. **Development:** Edit `frontend/.env.local` and set `VITE_MOONSHINE_MODEL=model/{name}`
2. **Production:** Update environment variable in Railway dashboard (requires rebuild)
3. **Dev Mode Testing:** Use the model selector (bottom-left corner in dev mode)

**Important:**

- Changing models requires a rebuild and redeploy
- Users only re-download when you **change which model** is used (e.g., tiny ‚Üí base)
- Regular app deployments (same model) do NOT require re-download - models stay cached
- Models are served from Moonshine CDN, independent of your app deployment

See [`frontend/docs/MOONSHINE_MODELS.md`](frontend/docs/MOONSHINE_MODELS.md) for detailed model comparison, performance metrics, and selection guidance.

### Running Tests

**Backend (pytest):**

```bash
cd backend
pip install -r requirements-dev.txt
pytest                    # Run all tests
pytest -v                 # Verbose output
pytest --cov=.            # With coverage report
pytest tests/test_lexical.py  # Run specific test file
```

**Frontend (Vitest):**

```bash
cd frontend
npm run test              # Run all tests
npm run test:watch        # Watch mode
npm run test:coverage     # With coverage report
```

**End-to-End (Playwright):**

```bash
cd e2e
npm install
npx playwright install    # Install browsers (first time)
npm test                  # Run all E2E tests
npm run test:ui           # Interactive UI mode
npm run test:debug        # Debug mode
npm run test:report       # View test report
```

**Linting:**

```bash
# Frontend
cd frontend
npm run lint              # ESLint
npm run lint:fix          # Auto-fix issues
npm run format            # Prettier
npm run format:check      # Check formatting

# Backend
cd backend
pip install -r requirements-dev.txt
ruff check .              # Lint
ruff check . --fix        # Auto-fix
ruff format .             # Format
```

### Git Hooks (Pre-commit)

The project uses [Husky](https://typicode.github.io/husky/) to automatically run linting and formatting on staged files before each commit. This is configured automatically when you run `npm install` (via the `prepare` script).

**What happens on commit:**

- Staged `.ts` and `.tsx` files are automatically linted with ESLint (auto-fix) and formatted with Prettier
- Staged `.css` and `.json` files are automatically formatted with Prettier
- If linting/formatting fails, the commit is blocked until issues are resolved

**No manual setup required** ‚Äî Git hooks are configured automatically during installation. If you need to manually reinstall hooks (e.g., after cloning), run:

```bash
npm install  # From project root (runs prepare script automatically)
# or
cd frontend && npm install  # From frontend directory
```

### Version Management

The project uses automated semantic versioning that increments on each new Pull Request.

**Automatic Versioning:**

- When a new PR is opened, the version is automatically incremented (patch version: `1.0.0` ‚Üí `1.0.1`)
- The version change is committed back to the PR branch
- A comment is posted on the PR showing the version change
- The version is stored in `frontend/package.json` and exposed in the app via `src/version.ts`

**Manual Versioning:**

You can also manually increment versions using npm scripts:

```bash
# Increment patch version (default: 1.0.0 ‚Üí 1.0.1)
npm run version
# or
npm run version:patch

# Increment minor version (1.0.0 ‚Üí 1.1.0)
npm run version:minor

# Increment major version (1.0.0 ‚Üí 2.0.0)
npm run version:major
```

The versioning script (`scripts/version.js`) updates both `frontend/package.json` and the root `package.json` (if it has a version field). The version is injected at build time via Vite and accessible in the browser console:

```javascript
// In browser console
window.__APP_VERSION__; // Full version object
window.version(); // Pretty formatted output
```

**GitHub Actions Workflow:**

The `.github/workflows/version.yml` workflow handles automatic versioning:

- Triggers on PR open (not on updates to avoid duplicate increments)
- Requires write permissions to commit back to the PR branch
- Uses the default `GITHUB_TOKEN` (should work automatically for same-repo PRs)

### Mobile Testing

Since prosodic detection is the core use case, testing on actual mobile devices is critical. Mobile browsers require **HTTPS for microphone access**, so use one of these methods:

#### Option A: LocalTunnel (Easiest)

```bash
# Terminal 1: Start dev server
cd frontend
npm run dev

# Terminal 2: Create HTTPS tunnel
npx localtunnel --port 5173
# Output: https://random-name.loca.lt

# Open the URL on your phone to test!
```

**Pros:** No configuration, instant HTTPS
**Cons:** Random URL changes each restart

#### Option B: ngrok (More Reliable)

```bash
# One-time install
brew install ngrok  # or: npm install -g ngrok

# Terminal 1: Start dev server
cd frontend
npm run dev

# Terminal 2: Create tunnel
ngrok http 5173
# Output: https://abc123.ngrok-free.app
```

**Pros:** Stable URLs (with account), better performance
**Cons:** Requires account for persistent URLs

#### Option C: Local Network (No Microphone)

```bash
# Start with network access
cd frontend
npm run dev -- --host

# Find your IP: ifconfig | grep "inet " (macOS/Linux)
# Access from phone: http://YOUR_IP:5173
```

‚ö†Ô∏è **Warning:** Microphone won't work on iOS/Safari without HTTPS

#### Mobile Testing Workflow

1. Start dev server with tunnel (Option A or B recommended)
2. Open tunnel URL on your phone
3. Use the model selector (visible in dev mode) to test different models
4. Record speech and test prosodic detection
5. Open browser console and run `window.viewMoonshineMetrics()` to see performance data
6. Compare load times and accuracy across models on real mobile connection

See [`frontend/docs/MOONSHINE_MODELS.md`](frontend/docs/MOONSHINE_MODELS.md) for model comparison and testing guidance.

## Features

- üé® Retro VU meter-style interface with animated needle
- üìù Text input with real-time analysis
- üé§ Audio recording with waveform visualization
- üîÑ Smooth loading state animations
- üì± Responsive design for mobile devices
- üê≥ Docker containerization for easy deployment

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## Local Docker Deployment

You can run the full application locally using Docker Compose. This mirrors the production environment but **does not support hot reload** ‚Äî use the [manual development setup](#manual-development-setup) if you need hot reload during development.

‚ö†Ô∏è **SECURITY WARNING:** The `docker-compose.yml` configuration is **for local testing only**. It uses `CORS_ORIGINS=http://localhost` which is permissive and **should never be used in production**.

**For production deployments:**

- Always override `CORS_ORIGINS` with your actual frontend domain(s)
- Use HTTPS URLs only (e.g., `https://yourdomain.com`)
- See [Deployment (Railway)](#deployment-railway) section for production setup

```bash
# Build and start all services
docker-compose up --build

# Access the application
open http://localhost

# Stop the services
docker-compose down
```

To rebuild after making changes:

```bash
# Rebuild and restart
docker-compose up --build

# Or rebuild a specific service
docker-compose up --build frontend
docker-compose up --build backend
```

### Customizing CORS for Local Testing

If you need to test with a custom domain locally (e.g., using a local domain like `sarcasm.local`):

1. Create a `.env` file in the project root:

   ```bash
   CORS_ORIGINS=http://sarcasm.local
   ```

2. Docker Compose will automatically load the `.env` file and override the default `http://localhost` value.

**Remember:** This is still for local testing only. Production deployments must use HTTPS and your actual domain.

### Build Arguments

The backend Dockerfile supports build arguments for cache management:

| Argument             | Default                       | Description                                      |
| -------------------- | ----------------------------- | ------------------------------------------------ |
| `WAV2VEC_CACHE_BUST` | `1`                           | Increment to force re-download of Wav2Vec2 model |
| `WAV2VEC_MODEL`      | `facebook/wav2vec2-base-960h` | Hugging Face model to use for audio embeddings   |

```bash
# Force re-download of Wav2Vec2 model (e.g., after model update)
docker-compose build --build-arg WAV2VEC_CACHE_BUST=2 backend

# Use a different Wav2Vec2 model
docker-compose build --build-arg WAV2VEC_MODEL=facebook/wav2vec2-large backend
```

## Deployment (Railway)

The application is deployed on [Railway](https://railway.app) with frontend and backend as separate services in one project.

### Prerequisites

- [Railway CLI](https://docs.railway.app/develop/cli) installed
- Railway account with access to the project

### Initial Setup

```bash
# Install Railway CLI (if not installed)
npm install -g @railway/cli

# Login to Railway
railway login
```

### Deploying

**Option A: From project root (using -s flag)**

```bash
cd Sarcasm-Detection
railway link  # Select: sarcasm ‚Üí production ‚Üí skip service
railway up -s Frontend
railway up -s Backend
```

**Option B: From within each folder**

```bash
# Deploy frontend
cd frontend
railway link  # Select: sarcasm ‚Üí production ‚Üí Frontend
railway up

# Deploy backend
cd ../backend
railway link  # Select: sarcasm ‚Üí production ‚Üí Backend
railway up
```

> **Note:** Root directories are configured in the Railway dashboard, not in `railway.toml`. Service names are case-sensitive.

### Environment Variables

Configure these in the Railway dashboard for each service:

**Frontend:**
| Variable | Description |
|----------|-------------|
| `VITE_API_URL` | Backend URL (e.g., `https://backend-production-xxxx.up.railway.app`) |
| `VITE_MOONSHINE_MODEL` | Speech model: `model/tiny` or `model/base` (default: `model/base`) |

**Backend:**
| Variable | Description |
|----------|-------------|
| `API_DELAY_SECONDS` | Set to `0` for production |
| `FLASK_ENV` | Set to `production` |
| `CORS_ORIGINS` | **REQUIRED** - Comma-separated list of allowed frontend origins (e.g., `https://sarcasm-detector.com`). Cannot be `*` in production. |

#### Changing Moonshine Model in Production

**Important Distinction:**

- **Same model + app update**: Users keep cached model ‚úÖ (instant load)
- **Different model**: Users must re-download ‚ùå (400MB for base)

Models are served from Moonshine CDN (`download.moonshine.ai`), not from your app. Regular deploys don't affect model caching.

**Process to Change Models:**

1. Navigate to Railway dashboard ‚Üí Frontend service ‚Üí Variables
2. Update `VITE_MOONSHINE_MODEL=model/{name}` (e.g., `model/base`)
3. Redeploy: `railway up -s Frontend` or push to main branch
4. Monitor first-user experience for load times (only affects users switching models)
5. Consider announcing model change if it significantly affects UX

**Example Timeline:**

- Day 1: Deploy with `model/base` ‚Üí Users download 400MB
- Day 5: Deploy bug fix (same `model/base`) ‚Üí Users load instantly from cache ‚úÖ
- Day 10: Switch to `model/tiny` ‚Üí Users download 190MB (new model)

**Model Selection Guidance:**

- **`model/base`** (400MB): Default - Best transcription accuracy for lexical detection
- **`model/tiny`** (190MB): Fastest, use if users report long load times

Note: Prosodic detection (audio analysis) is unaffected by transcription quality. Better models improve the lexical (text) component of sarcasm detection.

See [`frontend/docs/MOONSHINE_MODELS.md`](frontend/docs/MOONSHINE_MODELS.md) for detailed model comparison.

### Custom Domain

The frontend is configured with a custom domain (`sarcasm-detector.com`).

**DNS Setup (Namecheap):**

- Type: `ALIAS`
- Host: `@`
- Value: Railway's provided target (e.g., `xyz123.up.railway.app`)

**Railway Setup:**

- Custom domain port must be set to `8080` (Railway's internal port)
- Wait for TLS certificate to be issued (green checkmark)

> **Important:** When re-adding a custom domain, Railway may provide a new target. Always update your DNS to match.

---

## TODO / Future Improvements

### üé® CSS Variables Cleanup

Extract hardcoded "magic numbers" into CSS custom properties for maintainability:

**Spacing** (padding, margin, gap): ‚úÖ **Variables defined** ‚Äî `--space-micro`, `--space-small`, `--space-base`, `--space-medium`, `--space-large`, `--space-xl`, `--space-2xl`

- `0.375rem` (6px) ‚Äî micro | `0.56rem` (9px) ‚Äî small | `0.75rem` (12px) ‚Äî base
- `0.94rem` (15px) ‚Äî medium | `1.125rem` (18px) ‚Äî large | `1.5rem` (24px) ‚Äî xl | `1.875rem` (30px) ‚Äî 2xl
- **Status**: Variables added to `:root`, initial migration completed (~15 instances replaced). ~96 instances remain throughout the file.

**Border Radii:** ‚úÖ **Variables defined** ‚Äî `--radius-tiny`, `--radius-small`, `--radius-medium`, `--radius-large`

- `0.19rem` ‚Äî tiny (kbd) | `0.28rem` ‚Äî small (already `--border-radius-primary`)
- `0.45rem` ‚Äî medium (buttons) | `0.56rem` ‚Äî large (cards, modals)
- **Status**: Variables added to `:root`, initial migration completed (8 instances replaced).

**Animation Durations:**

- `100ms` ‚Äî micro | `140ms` ‚Äî hover | `160ms` ‚Äî quick | `180ms` ‚Äî standard | `350ms` ‚Äî views | `500ms` ‚Äî loading

**Font Sizes** (type scale):

- `0.49rem`, `0.56rem` ‚Äî tiny | `0.675rem`, `0.71rem` ‚Äî small | `0.75rem`, `0.83rem` ‚Äî base
- `0.94rem`, `1.05rem` ‚Äî medium | `1.125rem+` ‚Äî large/headings

**Shadows:** Button, card/modal, inset depth, brass/metallic highlights

**Suggested naming:** `--space-{xs,sm,md,lg,xl}`, `--radius-{sm,md,lg}`, `--duration-{fast,normal,slow}`, `--shadow-{sm,md,lg}`

### üéôÔ∏è Moonshine Model Optimization (Phase 2)

Phase 1 (completed): Switched to base model for better accuracy, added dev-only selector and telemetry.

Future Phase 2 options (data-driven decision):

- [ ] **Dynamic Model Selection**: Auto-detect network speed and load optimal model (tiny/base)
- [ ] **Progressive Loading**: Load tiny model first, upgrade to base in background for instant UX
- [ ] **Model Streaming**: Download models in chunks to improve perceived load time
- [ ] **Analytics Integration**: Track real user metrics to optimize model selection strategy

See [`frontend/docs/MOONSHINE_MODELS.md`](frontend/docs/MOONSHINE_MODELS.md) for detailed model comparison and trade-offs.

### üìù Other Improvements

- [ ] Add OpenAPI/Swagger documentation for API
- [ ] Performance monitoring/logging
- [ ] Model versioning and A/B testing support

---

## Known Issues

### MoonshineJS VAD Dependency Warning

The `@moonshine-ai/moonshine-js` package (v0.1.29) has a broken file path dependency on `@ricky0123/vad-web` that references a path only valid in their monorepo. Running `npm ls` will show an "invalid" warning.

**Impact:** None for this project. We disable VAD by passing `false` to the `MicrophoneTranscriber` constructor, so the vad-web code path is never executed. Both `npm install` and `npm run build` succeed.

**Status:** Known issue in the upstream package. Does not affect functionality.

### Occasional Layout Shift on Microphone Button

**Issue:** Very occasional layout shift occurs when users click the microphone button to start recording.

**Impact:** Minor visual glitch that happens infrequently. Does not affect functionality.

**Status:** Partially mitigated with CSS fixes (fixed dimensions, overflow handling, GPU acceleration). The occasional nature suggests it may be related to React state update timing or browser repaint cycles. A complete fix would likely require JavaScript-level coordination (debouncing state updates or requestAnimationFrame synchronization), which is more invasive.

**Technical Details:**

- Mic button wrapper reserves space for recording indicator overflow (8px padding)
- Fixed dimensions prevent most shifts
- Transform/GPU acceleration added to reduce repaint-related shifts
- Root cause likely involves timing between:
  - Flash animation stopping (`shouldFlash` prop change)
  - Recording indicator appearing (`isRecording` state change)
  - React re-renders and browser repaints

---

## License

MIT License - see [LICENSE](LICENSE) for details.

---

_Built with ‚ù§Ô∏è by signalflowsean_
