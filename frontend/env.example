# Copy this file to .env.local and fill in your values
# cp env.example .env.local

# Backend API URL (where the Flask backend is running)
VITE_API_URL=http://localhost:5000

# Moonshine speech recognition model - sets the default model for the app
# Options: model/tiny (~190MB, fast), model/base (~400MB, accurate)
#
# Default is model/base for better speech-to-text accuracy, which improves lexical detection.
# This value becomes the default in the model selector dropdown (dev mode only).
#
# IMPORTANT: If you change this, update the same variable in e2e/env.example to keep tests in sync.
# Both files now use VITE_MOONSHINE_MODEL with the 'model/' prefix format.
#
# See frontend/docs/MOONSHINE_MODELS.md for detailed model comparison.
#
VITE_MOONSHINE_MODEL=model/base

# Moonshine timeout configuration (in milliseconds)
#
# VITE_MOONSHINE_MODEL_TIMEOUT_MS: Maximum time to wait for model download and initialization
# Default: 120000 (2 minutes). Increase this for slow connections.
# Note: The base model is ~400MB, so on a 2 Mbps connection this can take 25+ minutes.
#
# VITE_MOONSHINE_VAD_TIMEOUT_MS: Maximum time to wait for VAD (Voice Activity Detection) initialization
# Default: 10000 (10 seconds). This is a fallback when there's silence during initialization.
#
# Uncomment and adjust these if you experience timeout errors on slow connections:
# VITE_MOONSHINE_MODEL_TIMEOUT_MS=300000
# VITE_MOONSHINE_VAD_TIMEOUT_MS=15000
